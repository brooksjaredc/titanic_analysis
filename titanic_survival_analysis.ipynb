{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  \n",
       "0       0         A/5 21171   7.2500   NaN        S  \n",
       "1       0          PC 17599  71.2833   C85        C  \n",
       "2       0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3       0            113803  53.1000  C123        S  \n",
       "4       0            373450   8.0500   NaN        S  \n",
       "5       0            330877   8.4583   NaN        Q  \n",
       "6       0             17463  51.8625   E46        S  \n",
       "7       1            349909  21.0750   NaN        S  \n",
       "8       2            347742  11.1333   NaN        S  \n",
       "9       0            237736  30.0708   NaN        C  \n",
       "10      1           PP 9549  16.7000    G6        S  \n",
       "11      0            113783  26.5500  C103        S  \n",
       "12      0         A/5. 2151   8.0500   NaN        S  \n",
       "13      5            347082  31.2750   NaN        S  \n",
       "14      0            350406   7.8542   NaN        S  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../titanic_data/train.csv')\n",
    "test = pd.read_csv('../titanic_data/test.csv')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = df['Sex'].astype('category').cat.codes\n",
    "df['Embarked'] = df['Embarked'].astype('category').cat.codes\n",
    "df['Cabin'] = df['Cabin'].astype('category').cat.codes\n",
    "df['Name_length'] = df.Name.apply(len)\n",
    "\n",
    "df['ms'] = df['Name'].str.contains(\"Miss. \")\n",
    "df['mr'] = df['Name'].str.contains(\"Mr. \")\n",
    "df['mrs'] = df['Name'].str.contains(\"Mrs. \")\n",
    "df['master'] = df['Name'].str.contains(\"Master. \")\n",
    "df['parenth'] = df['Name'].str.contains(\"\\(\")\n",
    "df['nickname'] = df['Name'].str.contains('\\\"')\n",
    "\n",
    "def get_element(my_list, position):\n",
    "    return my_list[position]\n",
    "\n",
    "df['ticket_num'] = df.Ticket.str.split(' ').apply(get_element, position=-1)\n",
    "df['ticket_num'] = df['ticket_num'].apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "df['ticket_letters'] = df.Ticket.str.split(' ').apply(get_element, position=0)\n",
    "df['ticket_letters'] = df['ticket_letters'].astype('category').cat.codes\n",
    "\n",
    "df['ticket_num'].fillna(0, inplace=True)\n",
    "df['Age'].fillna(150, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383838383838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name_length', 'ticket_num', 'Cabin',\n",
    "       'ms', 'mrs', 'mr', 'master', 'parenth', 'nickname']]\n",
    "#X = df[['Pclass', 'Sex', 'Age', 'Fare', 'Name_length', 'ticket_num']]\n",
    "#X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Name_length', 'ticket_num', 'Cabin',\n",
    "#       'ms', 'mrs', 'parenth']]\n",
    "\n",
    "# X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name_length', 'ticket_num', 'Cabin',\n",
    "#        'ms', 'mrs', 'mr', 'master', 'parenth', 'nickname', 'ticket_letters']]\n",
    "y = df['Survived']\n",
    "\n",
    "print(sum(y)/len(y))\n",
    "\n",
    "#print(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.770\n",
      "Precision: 0.848\n",
      "Accuracy: 0.857\n",
      "F1: 0.807\n",
      "[[124  12]\n",
      " [ 20  67]]\n",
      "Feature importances: [0.066 0.179 0.063 0.035 0.014 0.088 0.013 0.073 0.086 0.049 0.035 0.039\n",
      " 0.212 0.014 0.027 0.007]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 6, random_state=47).fit(X_train, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)\n",
    "print('Feature importances: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.782\n",
      "Precision: 0.829\n",
      "Accuracy: 0.852\n",
      "F1: 0.805\n",
      "[[122  14]\n",
      " [ 19  68]]\n",
      "Feature importances: [0.021 0.019 0.109 0.019 0.013 0.143 0.009 0.133 0.229 0.047 0.004 0.011\n",
      " 0.069 0.004 0.004 0.004 0.163]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, learning_rate = 0.01, \n",
    "                                 max_depth = 6, random_state=37).fit(X_train, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)\n",
    "print('Feature importances: {}'.format(clf.feature_importances_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.793\n",
      "Precision: 0.812\n",
      "Accuracy: 0.848\n",
      "F1: 0.802\n",
      "[[120  16]\n",
      " [ 18  69]]\n",
      "Feature importances: [0.008 0.045 0.128 0.054 0.032 0.170 0.007 0.070 0.344 0.059 0.000 0.027\n",
      " 0.011 0.023 0.003 0.019]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=1000, learning_rate = 0.1, \n",
    "                                 random_state=37).fit(X_train, y_train)\n",
    "\n",
    "y_predicted = clf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)\n",
    "print('Feature importances: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# we must apply the scaling to the test set that we computed for the training set\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_scaled_poly = poly.fit_transform(X_train_scaled)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled_poly = poly.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.784, 0.798, 0.811, 0.807, 0.807, 0.795, 0.771],\n",
       "       [0.822, 0.814, 0.808, 0.811, 0.789, 0.771, 0.738],\n",
       "       [0.814, 0.807, 0.801, 0.790, 0.749, 0.741, 0.720],\n",
       "       [0.810, 0.811, 0.793, 0.784, 0.753, 0.737, 0.704],\n",
       "       [0.814, 0.807, 0.801, 0.790, 0.749, 0.741, 0.720]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "grid_values = {'gamma': [0.001, 0.01, 0.05, 0.1, 1, 10, 100], 'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_values = {'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 10], 'C': [10, 100, 1000, 3000, 1000]}\n",
    "\n",
    "grid_clf = GridSearchCV(clf, param_grid = grid_values, scoring = 'accuracy')\n",
    "grid_clf.fit(X_train_scaled, y_train)\n",
    "grid_clf.cv_results_['mean_test_score'].reshape(5,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.618 0.618]\n",
      " [0.618 0.624]\n",
      " [0.618 0.769]\n",
      " [0.784 0.796]\n",
      " [0.813 0.816]\n",
      " [0.816 0.816]\n",
      " [0.810 0.810]\n",
      " [0.810 0.810]\n",
      " [0.810 0.810]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "lr = LogisticRegression()\n",
    "grid_values = {'penalty': ['l1', 'l2'], 'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "grid_lr = GridSearchCV(lr, param_grid = grid_values, scoring = 'accuracy').fit(X_train_scaled, y_train)\n",
    "print(grid_lr.cv_results_['mean_test_score'].reshape(9,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.759\n",
      "Precision: 0.825\n",
      "Accuracy: 0.843\n",
      "F1: 0.790\n",
      "[[122  14]\n",
      " [ 21  66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [50,50,50], solver='adam', alpha=0.00001, activation='identity',\n",
    "                     max_iter = 1000, random_state = 47).fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predicted = nnclf.predict(X_test_scaled)\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.678\n",
      "Precision: 0.843\n",
      "Accuracy: 0.825\n",
      "F1: 0.752\n",
      "[[125  11]\n",
      " [ 28  59]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predicted = knn.predict(X_test_scaled)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.816\n",
      "Precision: 0.732\n",
      "Accuracy: 0.812\n",
      "F1: 0.772\n",
      "[[110  26]\n",
      " [ 16  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nbclf = GaussianNB().fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predicted = nbclf.predict(X_test_scaled)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.747\n",
      "Precision: 0.812\n",
      "Accuracy: 0.834\n",
      "F1: 0.778\n",
      "[[121  15]\n",
      " [ 22  65]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "gpc = GaussianProcessClassifier(max_iter_predict=100, random_state=56).fit(X_train_scaled, y_train)\n",
    "\n",
    "y_predicted = gpc.predict(X_test_scaled)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "print('Recall: {:.3f}'.format(recall_score(y_test, y_predicted)))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_predicted)))\n",
    "print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_predicted)))\n",
    "print('F1: {:.3f}'.format(f1_score(y_test, y_predicted)))\n",
    "confusion = confusion_matrix(y_test, y_predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Sex'] = test['Sex'].astype('category').cat.codes\n",
    "test['Embarked'] = test['Embarked'].astype('category').cat.codes\n",
    "test['Cabin'] = test['Cabin'].astype('category').cat.codes\n",
    "test['Name_length'] = test.Name.apply(len)\n",
    "\n",
    "test['ms'] = test['Name'].str.contains(\"Miss. \")\n",
    "test['mr'] = test['Name'].str.contains(\"Mr. \")\n",
    "test['mrs'] = test['Name'].str.contains(\"Mrs. \")\n",
    "test['master'] = test['Name'].str.contains(\"Master. \")\n",
    "test['parenth'] = test['Name'].str.contains(\"\\(\")\n",
    "test['nickname'] = test['Name'].str.contains('\\\"')\n",
    "\n",
    "def get_element(my_list, position):\n",
    "    return my_list[position]\n",
    "\n",
    "test['ticket_num'] = test.Ticket.str.split(' ').apply(get_element, position=-1)\n",
    "test['ticket_num'] = test['ticket_num'].apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "test['ticket_num'].fillna(0, inplace=True)\n",
    "test['Age'].fillna(150, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Fare'].fillna(0, inplace=True)\n",
    "X_test = test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Name_length', 'ticket_num', 'Cabin',\n",
    "       'ms', 'mrs', 'mr', 'master', 'parenth', 'nickname']]\n",
    "\n",
    "\n",
    "# X_test = test[['Pclass', 'Sex', 'Age', 'SibSp', 'Fare', 'Name_length', 'ticket_num', 'Cabin',\n",
    "#        'ms', 'mrs', 'parenth']]\n",
    "\n",
    "#print(X_test)\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth = 5, random_state=47).fit(X, y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "# we must apply the scaling to the test set that we computed for the training set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "# knn.fit(X_train_scaled, y)\n",
    "\n",
    "# nnclf = MLPClassifier(hidden_layer_sizes = [5,5,5], solver='adam', alpha=0.0001, activation='identity',\n",
    "#                      max_iter = 1000, random_state = 47).fit(X_train_scaled, y)\n",
    "\n",
    "# y_predicted = nnclf.predict(X_test_scaled)\n",
    "\n",
    "#y_predicted = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier(n_estimators=100, max_depth = 6, random_state=47).fit(X, y)\n",
    "y_randomforest = randomforest.predict(X_test)\n",
    "\n",
    "gradientboosting = GradientBoostingClassifier(n_estimators=1000, learning_rate = 0.01, \n",
    "                                 max_depth = 6, random_state=37).fit(X, y)\n",
    "y_gradientboosting = gradientboosting.predict(X_test)\n",
    "\n",
    "adaboost = AdaBoostClassifier(n_estimators=1000, learning_rate = 0.1, \n",
    "                                 random_state=37).fit(X_train, y_train)\n",
    "y_adaboost = adaboost.predict(X_test)\n",
    "\n",
    "svm = SVC(kernel='rbf', C=100, gamma=0.01).fit(X_train_scaled, y)\n",
    "y_svm = svm.predict(X_test_scaled)\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=1.0).fit(X_train_scaled, y)\n",
    "y_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "nnclf = MLPClassifier(hidden_layer_sizes = [50,50,50], solver='adam', alpha=0.00001, activation='identity',\n",
    "                     max_iter = 1000, random_state = 47).fit(X_train_scaled, y)\n",
    "y_nnclf = nnclf.predict(X_test_scaled)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 15).fit(X_train_scaled, y)\n",
    "y_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "nbclf = GaussianNB().fit(X_train_scaled, y)\n",
    "y_nbclf = nbclf.predict(X_test_scaled)\n",
    "\n",
    "gpc = GaussianProcessClassifier(max_iter_predict=100, random_state=56).fit(X_train_scaled, y)\n",
    "y_gpc = gpc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000 0.571 0.000 0.000 0.857 0.000 0.857 0.000 1.000 0.000 0.000 0.000\n",
      " 1.000 0.000 1.000 1.000 0.000 0.000 0.714 1.000 0.000 1.000 1.000 0.000\n",
      " 1.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000 0.857 0.714 0.000 0.571\n",
      " 0.857 0.714 0.000 0.286 0.000 0.000 0.000 1.000 1.000 0.000 0.000 0.000\n",
      " 1.000 0.857 0.143 0.000 1.000 1.000 0.000 0.000 0.000 0.000 0.000 1.000\n",
      " 0.000 0.000 0.000 1.000 1.000 1.000 0.857 0.000 0.143 1.000 0.857 0.000\n",
      " 0.714 0.286 1.000 0.286 0.000 1.000 0.000 0.857 0.857 0.143 0.000 0.000\n",
      " 0.000 0.000 0.857 0.714 0.429 1.000 0.571 0.000 1.000 0.000 0.000 0.000\n",
      " 1.000 0.000 1.000 0.000 1.000 0.000 0.000 0.000 1.000 0.000 0.000 0.000\n",
      " 0.143 0.000 0.000 1.000 1.000 0.857 1.000 0.000 0.000 0.857 0.143 1.000\n",
      " 1.000 0.000 1.000 0.000 0.000 1.000 0.000 0.714 0.000 0.000 0.000 0.286\n",
      " 0.143 0.000 0.000 0.000 0.143 0.000 0.857 0.000 0.000 1.000 0.143 0.000\n",
      " 0.857 0.000 0.143 0.000 0.000 0.000 1.000 0.000 0.000 0.857 0.000 0.000\n",
      " 1.000 0.857 0.000 0.714 1.000 0.857 1.000 0.000 0.000 0.714 0.000 0.000\n",
      " 1.000 0.571 0.000 0.000 0.000 0.000 0.000 1.000 1.000 0.143 1.000 1.000\n",
      " 0.000 0.000 1.000 0.000 1.000 0.000 0.857 0.000 0.000 0.000 0.000 0.000\n",
      " 0.714 0.000 1.000 0.000 1.000 0.857 0.000 0.857 1.000 0.857 0.714 1.000\n",
      " 0.000 0.000 0.857 0.000 1.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000\n",
      " 1.000 0.143 1.000 0.000 1.000 0.000 1.000 0.000 1.000 1.000 0.000 1.000\n",
      " 0.000 0.000 0.000 1.000 0.000 0.000 0.000 0.000 0.000 0.000 1.000 1.000\n",
      " 1.000 1.000 0.143 0.000 0.571 0.000 1.000 0.000 1.000 1.000 1.000 0.000\n",
      " 0.429 0.000 0.000 0.000 0.000 0.000 1.000 0.000 0.000 0.000 1.000 0.714\n",
      " 0.000 0.000 0.000 0.000 0.857 0.000 0.286 0.000 1.000 1.000 0.000 1.000\n",
      " 0.000 0.000 0.000 0.000 0.714 0.714 0.857 1.000 0.714 0.000 0.000 0.000\n",
      " 0.000 0.143 0.000 0.857 0.000 0.000 0.000 0.000 1.000 0.000 0.000 0.000\n",
      " 0.000 0.000 0.000 0.000 1.000 1.000 0.286 1.000 0.143 0.571 0.000 0.000\n",
      " 0.000 0.714 1.000 0.857 0.286 0.000 0.000 0.000 0.000 0.143 0.143 0.000\n",
      " 1.000 0.000 1.000 1.000 0.000 0.000 1.000 0.000 0.000 1.000 0.000 0.143\n",
      " 0.000 0.000 0.000 0.857 0.000 0.000 0.000 1.000 0.714 0.857 0.000 1.000\n",
      " 0.000 1.000 1.000 0.000 0.000 0.000 1.000 0.000 1.000 0.000 0.000 0.857\n",
      " 0.000 1.000 1.000 0.000 1.000 0.143 0.000 0.857 1.000 0.000 0.000 1.000\n",
      " 0.000 0.000 1.000 1.000 0.429 0.143 0.000 0.143 0.000 0.000 1.000 0.857\n",
      " 0.143 1.000 0.000 0.000 0.000 0.000 0.143 1.000 0.857 0.000 0.000 1.000\n",
      " 0.000 1.000 0.000 0.000 1.000 0.000 1.000 0.000 0.143 0.857 0.000 0.143\n",
      " 1.000 0.857 0.857 1.000 0.714 0.000 1.000 0.000 0.000 0.857]\n",
      "0.255980861244\n",
      "             Survived\n",
      "PassengerId          \n",
      "892                 0\n",
      "893                 0\n",
      "894                 0\n",
      "895                 0\n",
      "896                 0\n",
      "897                 0\n",
      "898                 0\n",
      "899                 0\n",
      "900                 1\n",
      "901                 0\n",
      "902                 0\n",
      "903                 0\n",
      "904                 1\n",
      "905                 0\n",
      "906                 1\n",
      "907                 1\n",
      "908                 0\n",
      "909                 0\n",
      "910                 0\n",
      "911                 1\n",
      "912                 0\n",
      "913                 1\n",
      "914                 1\n",
      "915                 0\n",
      "916                 1\n",
      "917                 0\n",
      "918                 1\n",
      "919                 0\n",
      "920                 0\n",
      "921                 0\n",
      "...               ...\n",
      "1280                0\n",
      "1281                0\n",
      "1282                0\n",
      "1283                1\n",
      "1284                0\n",
      "1285                0\n",
      "1286                0\n",
      "1287                1\n",
      "1288                0\n",
      "1289                1\n",
      "1290                0\n",
      "1291                0\n",
      "1292                1\n",
      "1293                0\n",
      "1294                1\n",
      "1295                0\n",
      "1296                0\n",
      "1297                0\n",
      "1298                0\n",
      "1299                0\n",
      "1300                1\n",
      "1301                0\n",
      "1302                0\n",
      "1303                1\n",
      "1304                0\n",
      "1305                0\n",
      "1306                1\n",
      "1307                0\n",
      "1308                0\n",
      "1309                0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "n = 7.0\n",
    "threshold = 0.86\n",
    "\n",
    "# y_votes = (1.0/n)*(y_randomforest + y_gradientboosting + y_adaboost + \n",
    "#                    y_svm + y_lr + y_nnclf + y_knn + y_nbclf + y_gpc)\n",
    "y_votes = (1.0/n)*(y_randomforest + y_gradientboosting + \n",
    "                   y_svm + y_lr + y_nnclf + y_knn + y_nbclf)\n",
    "\n",
    "print(y_votes)\n",
    "\n",
    "low_values_flags = y_votes < threshold\n",
    "y_votes[low_values_flags] = 0.0\n",
    "\n",
    "high_values_flags = y_votes >= threshold\n",
    "y_votes[high_values_flags] = 1.0\n",
    "\n",
    "y_predictions = y_votes.astype(int)\n",
    "\n",
    "print(sum(y_predictions)/len(y_predictions))\n",
    "\n",
    "answer = pd.DataFrame(data=y_predictions, index = test['PassengerId'], columns=['Survived'])\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer.to_csv('/Users/jcbrooks/kaggle/titanic_analysis/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
